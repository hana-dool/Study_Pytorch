{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression",
      "provenance": [],
      "authorship_tag": "ABX9TyMxBwDa3CZxDJ8xVgyidSrP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hana-dool/Pytorch/blob/master/8.Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhO1o0O_mnJt",
        "colab_type": "text"
      },
      "source": [
        "# 로지스틱 회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCFhpwrRmL_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5fb8762-9983-4244-a3fd-ebd7977fddaf"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f237ef5f590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8Qwsx23v7a-",
        "colab_type": "text"
      },
      "source": [
        "## 직접 입력방식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GOAYl3CmkY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJH2YpJpmlyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d1ba12c0-2703-41a8-e10b-00cbc379f9d7"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 2])\n",
            "torch.Size([6, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OEF6PR6mykS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = torch.zeros((2, 1), requires_grad=True) # 크기는 2 x 1\n",
        "b = torch.zeros(1, requires_grad=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiCc4BgOm04G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 둘다 같은 식이다. torch 에서는 simgmoid 를 지원해준다.\n",
        "hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b))) # y_hat\n",
        "hypothesis = torch.sigmoid(x_train.matmul(W) + b) # "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7CFe18tm5EK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "d0d6d167-d50b-4dd3-e670-a0e392f28cc9"
      },
      "source": [
        "# 이때에 W,b 는 모두 0 으로 초기화 되어있는 상태이다. \n",
        "# 이 상태에서 예측값을 출력해보자.\n",
        "print(hypothesis)\n",
        "print(y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIGQrDyxnJ5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "61ca637f-84b9-4142-cf41-313a5e7be6c6"
      },
      "source": [
        "# loss 정의 , cost 정의\n",
        "losses = -(y_train * torch.log(hypothesis) + \n",
        "           (1 - y_train) * torch.log(1 - hypothesis))\n",
        "print(losses)\n",
        "cost = losses.mean()\n",
        "print(cost)\n",
        "\n",
        "F.binary_cross_entropy(hypothesis, y_train) # 로 바로 계산할수도있다."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931]], grad_fn=<NegBackward>)\n",
            "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKFOdmoyn170",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "a11e3f24-4f4d-47bb-9b5f-ee74dde7bc41"
      },
      "source": [
        "# 모델 변수설정\n",
        "W = torch.zeros((2,1),requires_grad=True)\n",
        "b = torch.zeros(1,requires_grad=True) \n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W,b], lr=1)\n",
        "\n",
        "# epoch 설정\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs+1) :\n",
        "    # y_hat 계산식\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis , y_train)\n",
        "    # cost 로 w update\n",
        "    optimizer.zero_grad() # 우선 기울기를 0 로 초기화해야한다.\n",
        "    cost.backward()  # 비용함수(cost)의 기울기를 계산해서 gradient 를 계산한다.\n",
        "    optimizer.step() # optimizer 에 저장한 방식으로 W,b 를 업데이트\n",
        "    # log 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {0:4d}/{1} Cost \"{2:.6f}'.format(epoch, nb_epochs, cost.item()))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 Cost \"0.693147\n",
            "Epoch  100/1000 Cost \"0.134722\n",
            "Epoch  200/1000 Cost \"0.080643\n",
            "Epoch  300/1000 Cost \"0.057900\n",
            "Epoch  400/1000 Cost \"0.045300\n",
            "Epoch  500/1000 Cost \"0.037261\n",
            "Epoch  600/1000 Cost \"0.031672\n",
            "Epoch  700/1000 Cost \"0.027556\n",
            "Epoch  800/1000 Cost \"0.024394\n",
            "Epoch  900/1000 Cost \"0.021888\n",
            "Epoch 1000/1000 Cost \"0.019852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF9UmjQ7r3WR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "084add27-48af-4a3b-878d-6c4b07fff1dd"
      },
      "source": [
        "# 예측\n",
        "# 현재 W,b 는 requires_grad 가 변하는것을 True 로 두었으므로, 예측값이 update 되어있는 상태이다.\n",
        "print(W)\n",
        "print(b)\n",
        "predict = torch.sigmoid(x_train.matmul(W) + b)\n",
        "predict > torch.FloatTensor([0.5])  #  예측 나름 잘하는듯?"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3.2530],\n",
            "        [1.5179]], requires_grad=True)\n",
            "tensor([-14.4819], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFFq8vWDsk91",
        "colab_type": "text"
      },
      "source": [
        "## nn.Mudule 이용\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdjBPJYCtUFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aCI6Pb8tWc0",
        "colab_type": "text"
      },
      "source": [
        "nn.Sequential()은 nn.Module 층을 차례로 쌓을 수 있도록 합니다. 뒤에서 이를 이용해서 인공 신경망을 구현하게 되므로 기억하고 있으면 좋습니다. 조금 쉽게 말해서 nn.Sequential()은 Wx+b와 같은 수식과 시그모이드 함수 등과 같은 여러 함수들을 연결해주는 역할을 합니다. 이를 이용해서 로지스틱 회귀를 구현해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3AFe5aWtcaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "   nn.Linear(2, 1), # input_dim = 2, output_dim = 1\n",
        "                    # Linear(2,1) 로 선언이 되어있으면, W,b 가 requres_grad = True 가 되어있는 상태로 초기화 되어서 자동으로 저장된다.\n",
        "   nn.Sigmoid() ) # 출력은 시그모이드 함수를 거친다 "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enMlKp99tnEs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "567ab600-8f9d-4c8b-eb8f-6db8e5dc22d2"
      },
      "source": [
        "print(list(model.parameters())) # 모델이 가지고 있는 파라미터 (W,b 출력) (랜덤초기화 되어있는상태)\n",
        "print(model(x_train)) # 예측값 .사실 가중치 초기화만 되어있고 학습은 안된상태라 의미는 없다."
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.3643, -0.3121]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1371], requires_grad=True)]\n",
            "tensor([[0.4020],\n",
            "        [0.4147],\n",
            "        [0.6556],\n",
            "        [0.5948],\n",
            "        [0.6788],\n",
            "        [0.8061]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm2j61QpuPuk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "017337d9-8959-4a13-832e-a310f0f0f191"
      },
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    # keras 랑은 다르게 직접 지정해주어야 하는듯...\n",
        "    if epoch % 100 == 0:\n",
        "        prediction = (hypothesis >= torch.FloatTensor([0.5])) # 예측값이 0.5를 넘으면 True로 간주\n",
        "        correct_prediction = (prediction.float() == y_train) # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "                                                                             # torch 에 하나의 값만 존재한다면, item 을 통해 값을 꺼낼 수 있다.\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 Cost: 0.005255 Accuracy 100.00\n",
            "Epoch  100/1000 Cost: 0.005129 Accuracy 100.00\n",
            "Epoch  200/1000 Cost: 0.005010 Accuracy 100.00\n",
            "Epoch  300/1000 Cost: 0.004896 Accuracy 100.00\n",
            "Epoch  400/1000 Cost: 0.004787 Accuracy 100.00\n",
            "Epoch  500/1000 Cost: 0.004683 Accuracy 100.00\n",
            "Epoch  600/1000 Cost: 0.004583 Accuracy 100.00\n",
            "Epoch  700/1000 Cost: 0.004487 Accuracy 100.00\n",
            "Epoch  800/1000 Cost: 0.004395 Accuracy 100.00\n",
            "Epoch  900/1000 Cost: 0.004307 Accuracy 100.00\n",
            "Epoch 1000/1000 Cost: 0.004223 Accuracy 100.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "racxX-AaumFS",
        "colab_type": "text"
      },
      "source": [
        "## 클래스로 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KR-fL0WvG7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "32c7b93a-40bf-4bf0-9793-348369c0d478"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f237ef5f590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il9Di3vwwpiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9utfJWrGwsWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # nn.Module 의 init 을 실행한 후 거기에다가 모델 추가\n",
        "        self.linear = nn.Linear(2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x): #  모델이 학습데이터를 입력받아서 forward 연산을 진행시키는 메서드\n",
        "        return self.sigmoid(self.linear(x)) # forward 부분의 함수연산\n",
        "model = BinaryClassifier()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP2FoXXiwtYp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "8e8929f6-a8db-4f3c-eb7c-f678da6f7a0d"
      },
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 Cost: 0.539713 Accuracy 83.33%\n",
            "Epoch  100/1000 Cost: 0.134272 Accuracy 100.00%\n",
            "Epoch  200/1000 Cost: 0.080486 Accuracy 100.00%\n",
            "Epoch  300/1000 Cost: 0.057820 Accuracy 100.00%\n",
            "Epoch  400/1000 Cost: 0.045251 Accuracy 100.00%\n",
            "Epoch  500/1000 Cost: 0.037228 Accuracy 100.00%\n",
            "Epoch  600/1000 Cost: 0.031649 Accuracy 100.00%\n",
            "Epoch  700/1000 Cost: 0.027538 Accuracy 100.00%\n",
            "Epoch  800/1000 Cost: 0.024381 Accuracy 100.00%\n",
            "Epoch  900/1000 Cost: 0.021877 Accuracy 100.00%\n",
            "Epoch 1000/1000 Cost: 0.019843 Accuracy 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XstQzUy3wOsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}