{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "클래스로 파이토치 모델구현.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgjRHRw1G37ByywL0WC5fx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hana-dool/Pytorch/blob/master/5.%ED%81%B4%EB%9E%98%EC%8A%A4%EB%A1%9C_%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%AA%A8%EB%8D%B8%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQTL-VHL5deK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg6XsqWd7rx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W9Rlc6A5Tax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleLinearRegression (torch.nn.Module):\n",
        "    def __init__(self): \n",
        "        super().__init__() # 자식클래스에서 부모클래스의 내용을 사용하고 싶은 경우 super().부모클래스내용\n",
        "                           # (이떄에는 init 을 사용하여서 부모클래스에서의 init 을 훔쳐서 attribute 형성하는것을 다 훔친다.)\n",
        "        self.linear = torch.nn.Linear(1,1) # attribute 형성, 이때에는 단순선형회귀 이므로 (1,1) 을 형성한다.\n",
        "    def forward (self, x): # 모델이 학습 데이터를 입력받아서 forward 연산을 진행시키는 메서드 \n",
        "        return self.linear(x)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysjtSGrJ5fSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델을 선언 및 초기화. \n",
        "model = SimpleLinearRegression()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiCvl06M7OR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DJ_lznx7ydY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "8846c30f-3095-4f17-ea76-68409afa28a5"
      },
      "source": [
        "# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.nn.functional.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "    # cost로 H(x) 개선하는 부분\n",
        "    # gradient를 0으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "    # 비용 함수를 미분하여 gradient 계산\n",
        "    cost.backward() # backward 연산\n",
        "    # W와 b를 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "    # 100번마다 로그 출력\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/2000 Cost: 21.826126\n",
            "Epoch  100/2000 Cost: 0.002206\n",
            "Epoch  200/2000 Cost: 0.001363\n",
            "Epoch  300/2000 Cost: 0.000842\n",
            "Epoch  400/2000 Cost: 0.000521\n",
            "Epoch  500/2000 Cost: 0.000322\n",
            "Epoch  600/2000 Cost: 0.000199\n",
            "Epoch  700/2000 Cost: 0.000123\n",
            "Epoch  800/2000 Cost: 0.000076\n",
            "Epoch  900/2000 Cost: 0.000047\n",
            "Epoch 1000/2000 Cost: 0.000029\n",
            "Epoch 1100/2000 Cost: 0.000018\n",
            "Epoch 1200/2000 Cost: 0.000011\n",
            "Epoch 1300/2000 Cost: 0.000007\n",
            "Epoch 1400/2000 Cost: 0.000004\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx1eCcJm71Aa",
        "colab_type": "text"
      },
      "source": [
        "# 다중선형회귀\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3sr_Bd98mUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ01jZpO8m8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultivariateLinearRegression(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(3, 1) # 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYBuVQp28qZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MultivariateLinearRegression()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApQkwH_d8xPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "abef8bfc-1c2b-41db-dd22-c155b3f1c2d4"
      },
      "source": [
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.nn.functional.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "    # cost로 H(x) 개선하는 부분\n",
        "    # gradient를 0으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "    # 비용 함수를 미분하여 gradient 계산\n",
        "    cost.backward()\n",
        "    # W와 b를 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "    # 100번마다 로그 출력\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/2000 Cost: 14429.984375\n",
            "Epoch  100/2000 Cost: 1.341283\n",
            "Epoch  200/2000 Cost: 1.290759\n",
            "Epoch  300/2000 Cost: 1.242811\n",
            "Epoch  400/2000 Cost: 1.197343\n",
            "Epoch  500/2000 Cost: 1.154228\n",
            "Epoch  600/2000 Cost: 1.113310\n",
            "Epoch  700/2000 Cost: 1.074507\n",
            "Epoch  800/2000 Cost: 1.037678\n",
            "Epoch  900/2000 Cost: 1.002753\n",
            "Epoch 1000/2000 Cost: 0.969604\n",
            "Epoch 1100/2000 Cost: 0.938152\n",
            "Epoch 1200/2000 Cost: 0.908303\n",
            "Epoch 1300/2000 Cost: 0.879962\n",
            "Epoch 1400/2000 Cost: 0.853090\n",
            "Epoch 1500/2000 Cost: 0.827557\n",
            "Epoch 1600/2000 Cost: 0.803322\n",
            "Epoch 1700/2000 Cost: 0.780301\n",
            "Epoch 1800/2000 Cost: 0.758452\n",
            "Epoch 1900/2000 Cost: 0.737713\n",
            "Epoch 2000/2000 Cost: 0.717995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrtBGdHG8zgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}